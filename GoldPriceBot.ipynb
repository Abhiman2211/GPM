{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import urllib\n",
    "import datetime\n",
    "import os\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "userBot = \"gpmbot\"\n",
    "pwdBot = \"9ALjKza5GmXqxMKNf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootUrl = \"https://darkroom.global-precious-metals.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drkrmLogin(user=userBot,password=pwdBot, rootUrl = rootUrl):\n",
    "    \"\"\"\n",
    "    login tryout\n",
    "    \"\"\"\n",
    "    apiLogin = \"/api/v1/login\"\n",
    "    data = {\"user\" : user, \"password\" : password}\n",
    "    r = requests.post(rootUrl+apiLogin,data=json.dumps(\n",
    "    data), headers={'Content-Type': 'application/json'})\n",
    "    if r.json()['status'] == 'success':\n",
    "        return r.json()['data']['userId'], r.json()['data']['authToken'] \n",
    "    else:\n",
    "        print(r.json())\n",
    "        raise Exception(\"Something went wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_message(msg, channel=\"#general\", user=userBot,password=pwdBot, rootUrl = rootUrl):\n",
    "    \"\"\"\n",
    "    we authenticate, then post\n",
    "    \"\"\"\n",
    "    apiMsg = \"/api/v1/chat.postMessage\"\n",
    "    userId, authToken = drkrmLogin(user=user, password=password, rootUrl=rootUrl)\n",
    "    payload = { \"channel\" : channel, \"text\" : msg}\n",
    "    response = requests.post(rootUrl+apiMsg,data=json.dumps(\n",
    "    payload), headers={'Content-Type': 'application/json', 'X-Auth-Token' : authToken, 'X-USer-Id' : userId})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCurl = \"https://www.dukascopy.com/swiss/english/home/?utm_source=freeserv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validatePath(path):\n",
    "    \"\"\"\n",
    "    Checks if path refers to a valid directory. If not an exception is raised.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        os.path.isfile(filename)\n",
    "    except:\n",
    "        raise NotADirectoryError(\"The specified path does not exist or is invalid. The data will be collected and stored in the current working directory in the file: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDukasTime(soup):\n",
    "    \"\"\"\n",
    "    Returns the extracted time as given on the DukasCopy webpage from where the DukasCopy data is being extracted from.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    soup (soup): The BeautifulSoup object containing the parsed HTML representation of the DukasCopy webpage.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    tdata = soup.find_all(\"span\", {\"id\": \"timeUpdate\"})\n",
    "    dtxt = tdata[0].text\n",
    "    \n",
    "    date_time_obj = datetime.datetime.strptime(dtxt, ' %a, %d %b %Y %H:%M:%S GMT')\n",
    "    \n",
    "    return date_time_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateData(NewFrame, filename):\n",
    "    \"\"\"\n",
    "    Updates the pickle file specified bt \"filepath\" by appending new data from the \"NewFrame\" dataframe to it.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    NewFrame (DataFrame): The dataframe which is to be appended to the end of the pickle file to update the pickle file with the new data.\n",
    "    filepath (str): The filepath of the pickle file where new dataframe data is to be appended.\n",
    "    \n",
    "    \"\"\"\n",
    "    if (not filename.endswith(\".pkl\")):\n",
    "        raise Exception(\"The filename specified must end with .pkl extension. The filename provided was: \" + filename)\n",
    "    \n",
    "    if not os.path.isfile(filename):\n",
    "        pd.to_pickle(NewFrame, filename)\n",
    "        \n",
    "    else:   \n",
    "        df = pd.read_pickle(filename)\n",
    "        df = df.append(NewFrame, sort=False)\n",
    "        df.to_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDukasCopyData(pathToChromeDriver):\n",
    "    \"\"\"\n",
    "    Returns a DataFrame object containing the most recent Gold Data from the DukasCopy website.\n",
    "    Scrapes the data from the DukasCopy website before formatting and returning the data as a pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    pathToChromeDriver (str): Path to the chromedriver executable to be used to open web pages.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: A pandas DataFrame containing the most recent Gold Data from the DukasCopy website.\n",
    "    \"\"\"\n",
    "    \n",
    "    browser = webdriver.Chrome(pathToChromeDriver)\n",
    "    browser.get(DCurl)\n",
    "    \n",
    "    DChtml = browser.page_source\n",
    "    soup = BeautifulSoup(DChtml, \"lxml\")\n",
    "    \n",
    "    # Finding the exact table with all the required data\n",
    "    data = soup.find_all(\"table\", {\"id\": \"list\"})\n",
    "    \n",
    "    # Creating and Modifying dataframe with the table \n",
    "    DCDataFrame = pd.read_html(str(data))[0]\n",
    "    \n",
    "    # Add a timestamp to the data\n",
    "    DCDataFrame[\"timestamp\"] = getDukasTime(soup)\n",
    "    \n",
    "    # Filter dataframe only to Gold Data\n",
    "    DCDataFrame = DCDataFrame[DCDataFrame[\"Live\"] == \"XAU/USD\"]\n",
    "    \n",
    "    browser.quit()\n",
    "    return DCDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchAndSaveDukas(filename, chromedriverpath):\n",
    "    \"\"\"\n",
    "    Fetches the most recent Gold Data from the DukasCopy website and updates the pickle file specified by \"dukasFilepath\" with the newest data.\n",
    "    If no pickle file with the specified name exists, a new one will be created.\n",
    "    If no filepath is specified, the current working directory will be used and data will be stored in the pickle file .\n",
    "    \n",
    "    Parameters:\n",
    "    dukasFilepath(str): The filepath to the pickle file where the fetched data will be stored.\n",
    "    chromedriverpath (str): Path to the chromedriver executable to be used to open web pages.\n",
    "    \"\"\"\n",
    "    df = getDukasCopyData(chromedriverpath)\n",
    "    updateData(df, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainDriver(dukaspath=\"DukasGoldData.pkl\", metalsApipath=\"MetalsAPIGoldData.pkl\", chromedriverpath=\"chromedriver.exe\"):\n",
    "    \"\"\"\n",
    "    Drives the entire code by calling the relevant methods and retrieves and stores the gold prices from the sources.\n",
    "    \n",
    "    Parameters:\n",
    "    dukaspath (str): Path to pickle file where you want to store the DukasCopy scraped data. If the pickle file with the specified name does not exist, it will be created in the specified directory.\n",
    "    metalsApipath (str): Path to pickle file where you want to store the DukasCopy scraped data. If the pickle file with the specified name does not exist, it will be created in the specified directory.\n",
    "    chromedriverpath (str): Path to the chromedriver executable to be used to open web pages.\n",
    "    \"\"\"\n",
    "    if dukaspath == metalsApipath:\n",
    "        raise Exception(\"The parameters dukaspath and metalsApipath cannot be the same.\")\n",
    "    \n",
    "    try:\n",
    "        validatePath(dukaspath)\n",
    "    except NotADirectoryError as e:\n",
    "        dukaspath = \"DukasGoldData.pkl\"\n",
    "        print(repr(e) + dukaspath)\n",
    "    \n",
    "    for i in range(5):\n",
    "        try:\n",
    "            fetchAndSaveDukas(dukaspath, chromedriverpath)\n",
    "        except Exception as e:\n",
    "            print(repr(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getNormalTime(t):\n",
    "    lst = t.split(\"T\")\n",
    "    return lst[1] + \" \" + lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sendPrices():\n",
    "    currData = getDukasCopyData(\"chromedriver.exe\")\n",
    "    \n",
    "    try:\n",
    "        timestamp = currData.iloc[0][\"timestamp\"]\n",
    "        bidPrice = currData.iloc[0][\"Bid\"]\n",
    "        askPrice = currData.iloc[0][\"Ask\"]\n",
    "    except:\n",
    "        print(\"Skipped here\")\n",
    "    \n",
    "    formattedMsg = \"GOLD PRICE as of \" + str(timestamp) + \"\\n \\n\" + \"Bid Price: \" + str(bidPrice) + \"\\nAsk Price: \" + str(askPrice)\n",
    "    \n",
    "    print(timestamp)\n",
    "    print(currData)\n",
    "    \n",
    "    post_message(formattedMsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def driver():\n",
    "    while True:\n",
    "        sendPrices()\n",
    "        time.sleep(7200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-09 09:41:23\n",
      "      Live      Bid      Ask  Spread           timestamp\n",
      "7  XAU/USD  1546.73  1547.01    27.7 2020-01-09 09:41:23\n"
     ]
    }
   ],
   "source": [
    "driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toto = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
